{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085b749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9557aa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05775ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6a49f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = tf.keras.layers.Input(shape=(256, 256, 3), name=\"encoder_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e60d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_conv_layer1 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", strides=1, name=\"encoder_conv_1\")(x)\n",
    "# encoder_norm_layer1 = tf.keras.layers.BatchNormalization(name=\"encoder_norm_1\")(encoder_conv_layer1)\n",
    "encoder_activ_layer1 = tf.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_1\")(encoder_conv_layer1)\n",
    "\n",
    "encoder_conv_layer2 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", strides=2, name=\"encoder_conv_2\")(encoder_activ_layer1)\n",
    "# encoder_norm_layer2 = tf.keras.layers.BatchNormalization(name=\"encoder_norm_2\")(encoder_conv_layer2)\n",
    "encoder_activ_layer2 = tf.keras.layers.LeakyReLU(name=\"encoder_activ_layer_2\")(encoder_conv_layer2)\n",
    "\n",
    "encoder_conv_layer3 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", strides=2, name=\"encoder_conv_3\")(encoder_activ_layer2)\n",
    "# encoder_norm_layer3 = tf.keras.layers.BatchNormalization(name=\"encoder_norm_3\")(encoder_conv_layer3)\n",
    "encoder_activ_layer3 = tf.keras.layers.LeakyReLU(name=\"encoder_activ_layer_3\")(encoder_conv_layer3)\n",
    "\n",
    "encoder_conv_layer4 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", strides=2, name=\"encoder_conv_4\")(encoder_activ_layer3)\n",
    "# encoder_norm_layer4 = tf.keras.layers.BatchNormalization(name=\"encoder_norm_4\")(encoder_conv_layer4)\n",
    "encoder_activ_layer4 = tf.keras.layers.LeakyReLU(name=\"encoder_activ_layer_4\")(encoder_conv_layer4)\n",
    "\n",
    "encoder_conv_layer5 = tf.keras.layers.Conv2D(filters=3, kernel_size=(3,3), padding=\"same\", strides=1, name=\"encoder_conv_5\")(encoder_activ_layer4)\n",
    "# encoder_norm_layer5 = tf.keras.layers.BatchNormalization(name=\"encoder_norm_5\")(encoder_conv_layer5)\n",
    "encoder_activ_layer5 = tf.keras.layers.LeakyReLU(name=\"encoder_activ_layer_5\")(encoder_conv_layer5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a84f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_before_flatten = tf.keras.backend.int_shape(encoder_activ_layer5)[1:]\n",
    "encoder_flatten = tf.keras.layers.Flatten()(encoder_activ_layer5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4115ae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_before_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42731872",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_dim = 500\n",
    "encoder_output = tf.keras.layers.Dense(units=latent_space_dim, name=\"encoder_output\")(encoder_flatten)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ea7e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tf.keras.models.Model(x,encoder_output, name=\"encoder_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cebdd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4f4308",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_vec_dim=100\n",
    "camera_input  = tf.keras.layers.Input(shape=(camera_vec_dim), name=\"camera_input\")\n",
    "camera_dense_layer1 = tf.keras.layers.Dense(units=500, name=\"camera_dense_1\",use_bias=False,activation=tf.keras.layers.LeakyReLU())(camera_input)\n",
    "camera_dense_layer2 = tf.keras.layers.Dense(units=500, name=\"camera_dense_2\",use_bias=False,activation=tf.keras.layers.LeakyReLU())(camera_dense_layer1)\n",
    "# camera_dense_layer3 = tf.keras.layers.Dense(units=500, name=\"camera_dense_3\",use_bias=False,kernel_initializer=initializer)(camera_dense_layer2)\n",
    "camera_dense_layer4 = tf.keras.layers.Dense(units=500, name=\"camera_dense_4\",use_bias=False,activation=tf.keras.layers.LeakyReLU())(camera_dense_layer2)\n",
    "camera_dense_layer5 = tf.keras.layers.Dense(units=500, name=\"camera_dense_5\",use_bias=False,activation=tf.keras.layers.LeakyReLU())(camera_dense_layer4)\n",
    "# camera_dense_layer6 = tf.keras.layers.Dense(units=500, name=\"camera_dense_6\")(camera_dense_layer5)\n",
    "camera_output = tf.keras.layers.Dense(units=(latent_space_dim), name=\"camera_output\")(camera_dense_layer5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9f9375",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_model = tf.keras.models.Model(camera_input,camera_output, name=\"camera_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a3844e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "camera_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785f5e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_model.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8b6cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(image_camera_enc):\n",
    "    img,cam = image_camera_enc\n",
    "    dense_input = img+cam\n",
    "    return dense_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b168657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input1 = tf.keras.layers.Input(shape=(latent_space_dim), name=\"decoder_input1\")\n",
    "decoder_input2 = tf.keras.layers.Input(shape=(latent_space_dim), name=\"decoder_input2\")\n",
    "concat_layer = tf.keras.layers.Lambda(concat,name = \"concat_layer\")([decoder_input1, decoder_input2])\n",
    "decoder_dense_layer1 = tf.keras.layers.Dense(units=np.prod(shape_before_flatten), name=\"decoder_dense_1\")(concat_layer)\n",
    "# decoder_dense_layer2 = tf.keras.layers.Dense(units=500, name=\"decoder_dense_2\",activation=\"relu\")(decoder_dense_layer1)\n",
    "# decoder_dense_layer3 = tf.keras.layers.Dense(units=np.prod(shape_before_flatten), name=\"decoder_dense_3\",activation=\"relu\")(decoder_dense_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faebea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_reshape = tf.keras.layers.Reshape(target_shape=shape_before_flatten)(decoder_dense_layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d495aff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_conv_tran_layer1 = tf.keras.layers.Conv2DTranspose(filters=256, kernel_size=(3, 3), padding=\"same\", strides=1, name=\"decoder_conv_tran_1\")(decoder_reshape)\n",
    "# decoder_norm_layer1 = tf.keras.layers.BatchNormalization(name=\"decoder_norm_1\")(decoder_conv_tran_layer1)\n",
    "decoder_activ_layer1 = tf.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_1\")(decoder_conv_tran_layer1)\n",
    "\n",
    "decoder_conv_tran_layer2 = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=(3, 3), padding=\"same\", strides=2, name=\"decoder_conv_tran_2\")(decoder_activ_layer1)\n",
    "# decoder_norm_layer2 = tf.keras.layers.BatchNormalization(name=\"decoder_norm_2\")(decoder_conv_tran_layer2)\n",
    "decoder_activ_layer2 = tf.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_2\")(decoder_conv_tran_layer2)\n",
    "\n",
    "decoder_conv_tran_layer3 = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), padding=\"same\", strides=2, name=\"decoder_conv_tran_3\")(decoder_activ_layer2)\n",
    "# decoder_norm_layer3 = tf.keras.layers.BatchNormalization(name=\"decoder_norm_3\")(decoder_conv_tran_layer3)\n",
    "decoder_activ_layer3 = tf.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_3\")(decoder_conv_tran_layer3)\n",
    "\n",
    "decoder_conv_tran_layer4 = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=(3, 3), padding=\"same\", strides=2, name=\"decoder_conv_tran_4\")(decoder_activ_layer3)\n",
    "# decoder_norm_layer4 = tf.keras.layers.BatchNormalization(name=\"decoder_norm_4\")(decoder_conv_tran_layer4)\n",
    "decoder_activ_layer4 = tf.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_4\")(decoder_conv_tran_layer4)\n",
    "\n",
    "decoder_output = tf.keras.layers.Conv2DTranspose(filters=3, kernel_size=(3, 3),activation=\"sigmoid\", padding=\"same\", strides=1, name=\"decoder_output\")(decoder_activ_layer4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f53c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = tf.keras.models.Model([decoder_input1,decoder_input2], decoder_output, name=\"decoder_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97462a68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6babaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_input1 = tf.keras.layers.Input(shape=(256, 256, 3), name=\"AE_input1\")\n",
    "ae_input2 = tf.keras.layers.Input(shape=(camera_vec_dim), name=\"AE_input2\")\n",
    "ae_encoder_output = encoder(ae_input1)\n",
    "ae_camera_output = camera_model(ae_input2)\n",
    "ae_decoder_output = decoder([ae_encoder_output,ae_camera_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa8be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = tf.keras.models.Model([ae_input1,ae_input2], ae_decoder_output, name=\"AE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ce2465",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d1bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "images=[]\n",
    "for i in range(0,43):\n",
    "    path = 'gtsd/Train/'+str(i)\n",
    "    img = os.listdir(path)\n",
    "    ch = random.sample(img,30)\n",
    "    for j in ch:\n",
    "        im = Image.open(path+\"/\"+j)\n",
    "        im = im.resize((256,256))\n",
    "        im = np.array(im)/255\n",
    "        images.append(im)\n",
    "\n",
    "img1 = Image.open(\"var_loss_img.jpg\")\n",
    "img1 = img1.resize((256,256))\n",
    "img1 = np.array(img1)/255\n",
    "images.append(img1)\n",
    "\n",
    "img1 = Image.open(\"rt_sign1.jpg\")\n",
    "img1 = img1.resize((256,256))\n",
    "img1 = np.array(img1)/255\n",
    "images.append(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6e1290",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c836f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_input_shape=100\n",
    "camera_params = np.zeros(shape=(camera_input_shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d176b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "while camera_params.shape[0]<=1800:\n",
    "    camera_params = np.vstack([camera_params,camera_params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c7c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_params = camera_params[:images.shape[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b31c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f69980",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f033bdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.compile(optimizer=\"adam\",loss=\"mse\",metrics=\"mape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f0ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,31):\n",
    "    ae.fit([images,camera_params],images,epochs=5,batch_size=8)\n",
    "    ae.save(\"auto_encoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777da547",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ae([images[200].reshape(1,256,256,3),tf.reshape(camera_params[0],[1,100])])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3bf83c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(images[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1402f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "num = []\n",
    "string =  os.listdir(\"sift_frames2\")\n",
    "for i in string:\n",
    "    numbers = re.findall(r'\\d+\\.\\d+|\\d+', i)\n",
    "    num.append(int(numbers[0]))\n",
    "image_num = sorted(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77409cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "captured_images=[]\n",
    "for i in range(0,len(image_num),10):\n",
    "    img = Image.open(\"sift_frames2/\"+str(image_num[i])+\".jpg\")\n",
    "    img = img.resize((256,256))\n",
    "    img = np.array(img)/255\n",
    "    captured_images.append(img)\n",
    "captured_images = np.array(captured_images)\n",
    "input_img = Image.open(\"var_loss_img.jpg\")\n",
    "input_img = input_img.resize((256,256))\n",
    "input_img = np.array(input_img)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8025a752",
   "metadata": {},
   "outputs": [],
   "source": [
    "captured_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc8b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_input = tf.keras.layers.Input(shape=(256, 256, 3), name=\"camer_input\")\n",
    "encoder_conv_layer1 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", strides=1, name=\"encoder_conv_1\")(camera_input)\n",
    "# encoder_norm_layer1 = tf.keras.layers.BatchNormalization(name=\"encoder_norm_1\")(encoder_conv_layer1)\n",
    "encoder_activ_layer1 = tf.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_1\")(encoder_conv_layer1)\n",
    "\n",
    "encoder_conv_layer2 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", strides=2, name=\"encoder_conv_2\")(encoder_activ_layer1)\n",
    "# encoder_norm_layer2 = tf.keras.layers.BatchNormalization(name=\"encoder_norm_2\")(encoder_conv_layer2)\n",
    "encoder_activ_layer2 = tf.keras.layers.LeakyReLU(name=\"encoder_activ_layer_2\")(encoder_conv_layer2)\n",
    "\n",
    "encoder_conv_layer3 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", strides=2, name=\"encoder_conv_3\")(encoder_activ_layer2)\n",
    "# encoder_norm_layer3 = tf.keras.layers.BatchNormalization(name=\"encoder_norm_3\")(encoder_conv_layer3)\n",
    "encoder_activ_layer3 = tf.keras.layers.LeakyReLU(name=\"encoder_activ_layer_3\")(encoder_conv_layer3)\n",
    "\n",
    "encoder_conv_layer4 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", strides=2, name=\"encoder_conv_4\")(encoder_activ_layer3)\n",
    "# encoder_norm_layer4 = tf.keras.layers.BatchNormalization(name=\"encoder_norm_4\")(encoder_conv_layer4)\n",
    "encoder_activ_layer4 = tf.keras.layers.LeakyReLU(name=\"encoder_activ_layer_4\")(encoder_conv_layer4)\n",
    "\n",
    "encoder_conv_layer5 = tf.keras.layers.Conv2D(filters=3, kernel_size=(3,3), padding=\"same\", strides=1, name=\"encoder_conv_5\")(encoder_activ_layer4)\n",
    "# encoder_norm_layer5 = tf.keras.layers.BatchNormalization(name=\"encoder_norm_5\")(encoder_conv_layer5)\n",
    "encoder_activ_layer5 = tf.keras.layers.LeakyReLU(name=\"encoder_activ_layer_5\")(encoder_conv_layer5)\n",
    "encoder_flatten = tf.keras.layers.Flatten()(encoder_activ_layer5)\n",
    "camera_output = tf.keras.layers.Dense(units=(camera_vec_dim), name=\"camera_output\")(encoder_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c117bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_cam = tf.keras.models.Model(camera_input,camera_output, name=\"gen_cam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01b1b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_cam.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14acdcac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_img = input_img.reshape(1,256,256,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb15501",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befaa53e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "camera_vectors=[]\n",
    "cam_loss=[]\n",
    "for epochs in range(1000):\n",
    "    out_img = captured_images[i]\n",
    "    X = captured_images[i].reshape(1,256,256,3)\n",
    "    for i in range(177): \n",
    "        out_img = captured_images[i]\n",
    "        X = captured_images[i].reshape(1,256,256,3)\n",
    "        with tf.GradientTape() as tape:\n",
    "            encoder.trainable=False\n",
    "            decoder.trainable=False\n",
    "            camera_model.trainable=False\n",
    "            gen_cam.trainable=True \n",
    "            camera_vector = gen_cam(X)\n",
    "            ae_output = ae([input_img,camera_vector])[0]\n",
    "            loss = tf.math.reduce_mean(tf.math.square(out_img-ae_output))\n",
    "        gradients = tape.gradient(loss, gen_cam.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, gen_cam.trainable_variables))\n",
    "        print(i,epochs,loss) \n",
    "        with tf.GradientTape() as tape1:\n",
    "            encoder.trainable=False\n",
    "            decoder.trainable=False\n",
    "            camera_model.trainable=True\n",
    "            gen_cam.trainable=False\n",
    "            camera_vector = gen_cam(X)\n",
    "            ae_output = ae([input_img,camera_vector])[0]\n",
    "            loss1 = tf.math.reduce_mean(tf.math.square(out_img-ae_output))\n",
    "        gradients = tape1.gradient(loss1, camera_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, camera_model.trainable_variables))\n",
    "        print(i,epochs,loss1) \n",
    "    camera_vectors.append(camera_vector.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650055d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"camera_vectors.npy\",camera_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a82595d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ff4d64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
